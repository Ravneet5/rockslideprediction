# -*- coding: utf-8 -*-
"""rock_slide_prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1C3lAFaZst_xEim8_Eq-xLVnlwBHesxNs

# LSTM (Tiltmeter)
"""

#importing libraries
from math import sqrt
from numpy import concatenate
from matplotlib import pyplot
from pandas import read_csv
from pandas import DataFrame
from pandas import concat
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import mean_squared_error
import matplotlib.pyplot as plt
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import LSTM
import pandas as pd
from keras.callbacks import EarlyStopping
from keras.callbacks import EarlyStopping
from keras.optimizers import Adam
from keras.optimizers import SGD

# Loading data from Excel file
file_path = "/content/TM_combine_data.xlsx"
dataset = pd.read_excel(file_path, header=0, index_col=0)
dataset.shape

dataset.head()

values = dataset.values
print(type(values))
print(values[0])

scaler = StandardScaler()
scaled = scaler.fit_transform(values)
print(scaled[:2,:])

def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):
    n_vars = data.shape[1]
    df = DataFrame(data)
    cols, names = list(), list()

    # Input sequence (t-n, ... t-1)
    for i in range(n_in, 0, -1):
        cols.append(df.shift(i))
        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]

    # Forecast sequence (t, t+1, ... t+n)
    for i in range(0, n_out):
        cols.append(df.shift(-i))
        if i == 0:
            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]
        else:
            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]

    # Putting it all together
    agg = concat(cols, axis=1)
    agg.columns = names
    if dropnan:
        agg.dropna(inplace=True)
    return agg

n_previous = 10
n_features = 30
reframed = series_to_supervised(scaled, n_previous, 1)
reframed.head()

values = reframed.values
values.shape

split_ratio = 0.7
n_train_samples = int(len(values) * split_ratio)

train = values[:n_train_samples, :]
test = values[n_train_samples:, :]
print("size of training and testing dataset :",train.shape,test.shape)

n_obs = n_previous * n_features
train_X, train_y = train[:, :n_obs], train[:, -n_features:]
test_X, test_y = test[:, :n_obs], test[:, -n_features:]
print(f"n_obs={n_obs}\ntrain_X shape: {train_X.shape}, \ntrain_y shape: {train_y.shape} \ntest_X.shape: {test_X.shape} \ntest_y.shape: {test_y.shape} ")

train_X = train_X.reshape((train_X.shape[0], n_previous, n_features))
test_X = test_X.reshape((test_X.shape[0], n_previous, n_features))
print(train_X.shape)
print(train_y.shape)
print(test_X.shape)
print(test_y.shape)

from keras.models import Sequential
from keras.layers import LSTM, Dense, Dropout, Bidirectional

model = Sequential()
model.add(Bidirectional(LSTM(128, return_sequences=True,activation='relu'), input_shape=(train_X.shape[1], train_X.shape[2])))
model.add(LSTM(64))
model.add(Dropout(0.5))
model.add(Dense(n_features))
model.compile(loss='mae', optimizer="adam", metrics=['mae'])

early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)

history = model.fit(train_X, train_y, epochs=50, batch_size=36, validation_data=(test_X, test_y), verbose=2, shuffle=False,callbacks=early_stopping)

plt.plot(history.history['loss'], label='train')
plt.plot(history.history['val_loss'], label='test')
plt.legend()
plt.show()

yhat = model.predict(test_X)

inv_yhat = scaler.inverse_transform(yhat)

inv_y = scaler.inverse_transform(test_y)

plt.figure(figsize=(20, 10))
plt.plot(inv_y[:100, 0], label="original")
plt.plot(inv_yhat[:100, 0], label="predicted")
plt.legend()
plt.show()

header_values = dataset.columns

def plot_predictions(original, predicted, header, num_columns=30):
    plt.figure(figsize=(20, 40))
    for i in range(num_columns):
        plt.subplot(num_columns, 1, i + 1)
        plt.plot(original[:, i], label='Original')
        plt.plot(predicted[:, i], label='Predicted')
        plt.title(header[i])
        plt.legend()
    plt.tight_layout()
    plt.show()

plot_predictions(inv_y, inv_yhat, header_values ,num_columns=n_features)

"""# Prophet (Tiltmeter)"""

import pandas as pd
from pandas import to_datetime, DataFrame
from prophet import Prophet
from matplotlib import pyplot as plt

path = '/content/TM_combine_data.xlsx'
df = pd.read_excel(path, header=0)

columns_to_process = [df.columns[i:i+30] for i in range(0, len(df.columns), 30)]

# Preparing columns for prediction
future = []
for year in range(2023, 2024):
    for month in range(11, 12):
        for day in range(24, 30):
            for hour in range(0, 24):
                for minute in range(0, 60, 15):
                    date = f'{day:02d}-{month:02d}-{year:04d} {hour:02d}:{minute:02d}'
                    future.append([date])
for year in range(2023, 2024):
    for month in range(12, 13):
        for day in range(1, 30):
            for hour in range(0, 24):
                for minute in range(0, 60, 15):
                    date = f'{day:02d}-{month:02d}-{year:04d} {hour:02d}:{minute:02d}'
                    future.append([date])
for year in range(2024, 2025):
    for month in range(1, 3):
        for day in range(1, 30):
            for hour in range(0, 24):
                for minute in range(0, 60, 15):
                    date = f'{day:02d}-{month:02d}-{year:04d} {hour:02d}:{minute:02d}'
                    future.append([date])

future_df = DataFrame(future, columns=['ds'])
future_df['ds'] = to_datetime(future_df['ds'], format='%d-%m-%Y %H:%M')

# Iterating over each set of columns and apply the model
for i, columns in enumerate(columns_to_process):
    if 'Date Time (UTC+08:00)' in columns:
        columns_to_keep = ['Date Time (UTC+08:00)'] + list(columns[1:31])
        df_subset = df[columns_to_keep].copy()
        df_subset.columns = ['ds'] + [f'y_{i}' for i in range(1, len(columns_to_keep))]

        for j in range(1, len(df_subset.columns)):
            original_column_name = df_subset.columns[j]
            df_feature = df_subset[['ds', original_column_name]].copy()
            df_feature.columns = ['ds', 'y']
            df_feature['ds'] = to_datetime(df_feature['ds'], errors='coerce')
            df_feature = df_feature.dropna(subset=['ds'])

            # Checking if any NaN values in the 'ds' column
            if df_feature['ds'].isnull().any():
                print(f'Skipping column {original_column_name} due to NaN values in "ds" after conversion.')
                continue

            model = Prophet()
            model.fit(df_feature)

            forecast = model.predict(future_df)

            plt.figure(figsize=(10, 6))
            plt.plot(df_feature['ds'], df_feature['y'], label='Original')

            model.plot(forecast, ax=plt.gca(), xlabel='Date', ylabel='Value')

            plt.title(f'Forecast for Column {original_column_name}')
            plt.legend()
            plt.show()

"""#LSTM (Crackmeter)"""

from math import sqrt
from numpy import concatenate
from matplotlib import pyplot
from pandas import read_csv
from pandas import DataFrame
from pandas import concat
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import mean_squared_error
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import LSTM
from pandas import read_excel
from matplotlib import pyplot
from sklearn.preprocessing import StandardScaler

file_path = "/content/CM_Combine_Data.xlsx"
dataset = read_excel(file_path, header=0, index_col=0)
values = dataset.values

def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):
	n_vars = 1 if type(data) is list else data.shape[1]
	df = DataFrame(data)
	cols, names = list(), list()
	for i in range(n_in, 0, -1):
		cols.append(df.shift(i))
		names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]
	for i in range(0, n_out):
		cols.append(df.shift(-i))
		if i == 0:
			names += [('var%d(t)' % (j+1)) for j in range(n_vars)]
		else:
			names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]

	agg = concat(cols, axis=1)
	agg.columns = names

	if dropnan:
		agg.dropna(inplace=True)
	return agg


scaler = StandardScaler()
scaled = scaler.fit_transform(values)
n_previous = 20
n_features = 12
reframed = series_to_supervised(scaled, n_previous, 1)
values = reframed.values


split_ratio = 0.7
n_train_samples = int(len(values) * split_ratio)


train = values[:n_train_samples, :]
test = values[n_train_samples:, :]
n_obs = n_previous*n_features
train_X, train_y = train[:, :n_obs], train[:, -n_features:]
test_X, test_y = test[:, :n_obs], test[:, -n_features:]

train_X = train_X.reshape((train_X.shape[0], n_previous, n_features))
test_X = test_X.reshape((test_X.shape[0], n_previous, n_features))



model = Sequential()
model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))
model.add(Dense(n_features))
model.compile(loss='mae', optimizer='adam')

history = model.fit(train_X, train_y, epochs=20, validation_data=(test_X, test_y), verbose=1, shuffle=False)

pyplot.plot(history.history['loss'], label='train')
pyplot.plot(history.history['val_loss'], label='test')
pyplot.legend()
pyplot.show()


# Make a prediction
yhat = model.predict(test_X)
import matplotlib.pyplot as plt
# Invert scaling for forecast
inv_yhat = scaler.inverse_transform(yhat)

# Invert scaling for actual
inv_y = scaler.inverse_transform(test_y)

# Plot the results
plt.figure(figsize=(20, 10))
plt.plot(inv_y[:100, 0], label="original")
plt.plot(inv_yhat[:100, 0], label="predicted")
plt.legend()
plt.show()

header_values = dataset.columns

# Function to plot predictions for all columns
def plot_predictions(original, predicted, header, num_columns=12):
    plt.figure(figsize=(20, 40))
    for i in range(num_columns):
        plt.subplot(num_columns, 1, i + 1)
        plt.plot(original[:, i], label='Original')
        plt.plot(predicted[:, i], label='Predicted')
        plt.title(header_values[i])
        plt.legend()
    plt.tight_layout()
    plt.show()

# Plot predictions for all columns
plot_predictions(inv_y, inv_yhat, header_values, num_columns=n_features)

"""#Prophet(Crackmeter)"""

import pandas as pd
from pandas import to_datetime, DataFrame
from prophet import Prophet
from matplotlib import pyplot as plt
path = '/content/TM_combine_data.xlsx'
df = pd.read_excel(path, header=0)

columns_to_process = [df.columns[i:i+12] for i in range(0, len(df.columns), 12)]

future = []
for year in range(2023, 2024):
    for month in range(11, 12):
        for day in range(24, 30):
            for hour in range(0, 24):
                for minute in range(0, 60, 15):
                    date = f'{day:02d}-{month:02d}-{year:04d} {hour:02d}:{minute:02d}'
                    future.append([date])
for year in range(2023, 2024):
    for month in range(12, 13):
        for day in range(1, 30):
            for hour in range(0, 24):
                for minute in range(0, 60, 15):
                    date = f'{day:02d}-{month:02d}-{year:04d} {hour:02d}:{minute:02d}'
                    future.append([date])
for year in range(2024, 2025):
    for month in range(1, 3):
        for day in range(1, 30):
            for hour in range(0, 24):
                for minute in range(0, 60, 15):
                    date = f'{day:02d}-{month:02d}-{year:04d} {hour:02d}:{minute:02d}'
                    future.append([date])

future_df = DataFrame(future, columns=['ds'])
future_df['ds'] = to_datetime(future_df['ds'], format='%d-%m-%Y %H:%M')

for i, columns in enumerate(columns_to_process):
    if 'Date Time (UTC+08:00)' in columns:
        columns_to_keep = ['Date Time (UTC+08:00)'] + list(columns[1:13])
        df_subset = df[columns_to_keep].copy()
        df_subset.columns = ['ds'] + [f'y_{i}' for i in range(1, len(columns_to_keep))]

        # Iterating over each feature column and apply the model
        for j in range(1, len(df_subset.columns)):
            original_column_name = df_subset.columns[j]
            df_feature = df_subset[['ds', original_column_name]].copy()
            df_feature.columns = ['ds', 'y']

            # Convert 'ds' to datetime and drop rows with NaN values
            df_feature['ds'] = to_datetime(df_feature['ds'], errors='coerce')
            df_feature = df_feature.dropna(subset=['ds'])

            # Check for any NaN values in the 'ds' column
            if df_feature['ds'].isnull().any():
                print(f'Skipping column {original_column_name} due to NaN values in "ds" after conversion.')
                continue

            model = Prophet()
            model.fit(df_feature)

            # Make predictions
            forecast = model.predict(future_df)
            plt.figure(figsize=(10, 6))
            plt.plot(df_feature['ds'], df_feature['y'], label='Original')

            model.plot(forecast, ax=plt.gca(), xlabel='Date', ylabel='Value')
            plt.title(f'Forecast for Column {original_column_name}')
            plt.legend()
            plt.show()